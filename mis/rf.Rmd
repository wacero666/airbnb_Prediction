---
title: "tester"
author: "Minyue Fan"
date: "4/23/2019"
output: pdf_document
---


```{r}
library(dplyr)
library(ggplot2)
library(randomForest)

#price <- read.csv("price.csv")
```



```{r}
price_train<- read.csv("price_train.csv")
price_val<- read.csv("price_val.csv")
price_train <- price_train[, -c(1,2)]
price_val <- price_val[, -c(1,2)]
full_data <- rbind(price_train, price_val)
```



```{r}
price_test <- read.csv("price_test_cleaned.csv")
price_test<- price_test[, -c(1,2)]
dim(price_test)
```




```{r}
dim(price_val)
```


# Attempt 1: lm
```{r}
# base line lm

base_model <- lm(price ~ . , data= price_train)
# train error 
print("train error")
mean((base_model$fit - price_train$price)^2)
# test error
print("test error")
mean((predict(base_model,price_val)- price_val$price)^2)
```

# Out of BAG  RF

```{r}

set.seed(123)
m1 <- randomForest(
  formula = price ~ .,
  data = full_data
)

```



```{r}
# number of trees with lowest MSE
which.min(m1$mse)
## [1] 344

# RMSE of this optimal random forest
m1$mse[which.min(m1$mse)]

```

```{r}
plot(m1)
```






```{r}
m2 <- randomForest(
  formula = price ~ .,
  data = full_data,
   ntree= 200
)
```


```{r}
mean((m2$predicted - full_data$price)^2)
```

```{r}
pred <- predict(m2, price_test[,colnames(price_test)!="price"])
mean((pred-price_test$price)^2)
```










# Attempt 3: Random Forrest
```{r}
library(randomForest)
library(dplyr)

#rf1 <- randomForest(formula = price~., data = price_train)

xval <- price_val[,-which((names(price_val)) == 'price')]
yval <- price_val[,which((names(price_val)) == 'price')]
#plot(rf1)

#price_train %>% arrange(desc(price))
# baseline: fit on all variables 
rf_oob_comp_0 <- randomForest(formula = price~., data = price_train, xtest = xval, ytest = yval,importance=TRUE)
```
```{r}
plot_mse <- function(train_mse, test_mse){
 
  plot(c(1:length(train_mse)), train_mse, col="red", type="l",   ylab="mse", xlab="tree")
  lines(c(1:length(test_mse)),test_mse, col="blue") 
  legend("topright", legend = c("train", "val"), col=c("blue", "red"), lty=c(1,1))
  
}
```





```{r}
get_mse <- function(rf_oob_comp_0){
  train.error_0 <-rf_oob_comp_0$mse
  val.error_0 <- rf_oob_comp_0$test$mse
  return(list(train.error_0,val.error_0))
}
plot_mse(get_mse(rf_oob_comp_0)[[1]], get_mse(rf_oob_comp_0)[[2]])
```

#Tuning
```{r}
#mtry 7.3
set.seed(123)

m3 <- tuneRF(
  x          = full_data[,colnames(full_data)!="price"],
  y          = full_data$price,
  ntreeTry   = 500,
  mtryStart  = 5,
  stepFactor = 1.5,
  improve    = 0.01,
  trace      = FALSE      # to not show real-time progress 
)
```


# ranger 

```{r}
# randomForest speed
library(ranger)
n_features <- ncol(full_data)

##    user  system elapsed 
##  55.371   0.590  57.364

# ranger speed
system.time(
  ames_ranger <- ranger(
    formula   = price ~ ., 
    data      = full_data, 
    num.trees = 500,
    mtry      = floor(n_features  / 3)
  )
)
```

```{r}
# hyperparameter grid search
hyper_grid <- expand.grid(
  mtry       = c(6, 7, 8),
  node_size  = c(10, 20, 100, 200, 300),
  sampe_size = c(0.55, .632, .70, .80),
  OOB_RMSE   = 0,
  mtree      = c(200, 300, 400, 500)
) 

# total number of combinations
nrow(hyper_grid)
```

```{r}
for(i in 1:nrow(hyper_grid)) {
  
  # train model

  model <- ranger(
    formula   = price ~ ., 
    data            = full_data, 
    num.trees       = hyper_grid$mtree[i],
    mtry            = hyper_grid$mtry[i],
    min.node.size   = hyper_grid$node_size[i],
    sample.fraction = hyper_grid$sampe_size[i],
    seed            = 123
    
  )
  
  # add OOB error to grid
  hyper_grid$OOB_RMSE[i] <- mean(model$prediction.error)
  
}

```

```{r}

hyper_grid %>% 
  dplyr::arrange(OOB_RMSE)
```
#importance
```{r}

model4 <- ranger(
    formula   = price ~ ., 
    data            = full_data, 
    num.trees       = 500,
    mtry            = 5,
    min.node.size   = 10,
    sample.fraction = 0.8,
    seed            = 123,
    importance = "impurity"
  )
  
  # add OOB error to grid
mean(model4$prediction.error)

```

```{r}

saveRDS(model4, "./m4_model.rds")

# later...

# load the model
super_model <- readRDS("./m4_model.rds")
```
```{r}
imp <- super_model$variable.importance
var_importance <- data.frame(variable=names(imp),
                             importance=as.vector(imp))
var_importance <- arrange(var_importance, importance)
var_importance$variable <- factor(var_importance$variable, levels=var_importance$variable)

p <- ggplot(var_importance, aes(x=variable, weight=importance))
p <- p + geom_bar() + coord_flip() + ylab("Variable Importance")
p <- p + scale_fill_discrete(name="Variable Name") + ggtitle("Variable Importance from Random Forest Fit")
p + theme_bw() + 
  theme(axis.text = element_text(color = "darkslategrey"),
        text = element_text(color = "black", size = 10), legend.key.size = unit(5, "lines"))

```


```{r}
selected_val <- var_importance$variable[-c(1:4)]
```


```{r}

model5 <- ranger(
    formula   = price ~ ., 
    data            = full_data[,selected_val], 
    num.trees       = 500,
    mtry            = 7,
    min.node.size   = 10,
    sample.fraction = 0.8,
    seed            = 123,
    importance = "impurity"
  )
  
  # add OOB error to grid
mean(model5$prediction.error)

```









```{r}
imp <- importance(rf_oob_comp_0, type=2)
var_importance <- data.frame(variable=row.names(imp),
                             importance=as.vector(imp))
var_importance <- arrange(var_importance, importance)
var_importance$variable <- factor(var_importance$variable, levels=var_importance$variable)

p <- ggplot(var_importance, aes(x=variable, weight=importance))
p <- p + geom_bar() + coord_flip() + ylab("Variable Importance")
p <- p + scale_fill_discrete(name="Variable Name") + ggtitle("Variable Importance from Random Forest Fit")
p + theme_bw() + 
  theme(axis.text = element_text(color = "darkslategrey"),
        text = element_text(color = "black", size = 10), legend.key.size = unit(5, "lines"))

```

# select variable on random forest

```{r}
select_var <- c(as.vector(var_importance$variable[c(8:22)]), "price")
```

```{r}
select_train <- price_train[, select_var]
select_val <- price_val[, select_var]
slect_full <- full_data[, select_var]


select_rf <- randomForest(formula = price~., 
                          ntree       = 500,
                          mtry      = 7,
                          nodesize   = 10,
                          
                            data = slect_full,
                          importance = TRUE)

```

```{r}
# number of trees with lowest MSE
which.min(select_rf$mse)

# RMSE of this optimal random forest
select_rf$mse[which.min(m1$mse)]

```

```{r}
plot(select_rf)
```


```{r}
imp <- importance(select_rf, type=2)
var_importance <- data.frame(variable=row.names(imp),
                             importance=as.vector(imp))
var_importance <- arrange(var_importance, importance)
var_importance$variable <- factor(var_importance$variable, levels=var_importance$variable)

p <- ggplot(var_importance, aes(x=variable, weight=importance))
p <- p + geom_bar() + coord_flip() + ylab("Variable Importance")
p <- p + scale_fill_discrete(name="Variable Name") + ggtitle("Variable Importance from Random Forest Fit")
p + theme_bw() + 
  theme(axis.text = element_text(color = "darkslategrey"),
        text = element_text(color = "black", size = 10), legend.key.size = unit(5, "lines"))

```
```{r}
select_rf_1 <- randomForest(formula = price~., 
                          ntree       = 223,
                          mtry      = 4.7,
                          nodesize   = 10,
                            data = slect_full,
                          importance = TRUE)

```

```{r}
final_predictions <- predict(select_rf_1, price_test[, colnames(price_test)!="price"])
mean((final_predictions - price_test$price)^2)
```





# try caret tunning
```{r}
library(randomForest)
library(mlbench)
library(caret)
library(e1071)
control <- trainControl(method='repeatedcv', 
                        number=5, 
                        repeats=3)
set.seed(123)
#Number randomely variable selected is mtry
mtry <- sqrt(ncol(full_data))
tunegrid <- expand.grid(.mtry=mtry)
rf_default <- train(price~., 
                      data=full_data, 
                      method="rf", metric="RMSE", 
                      tuneGrid=tunegrid, 
                      trControl=control)
print(rf_default)
```

```{r}
rf_default$results
```


```{r}
mtry <- sqrt(ncol(full_data))
#ntree: Number of trees to grow.
ntree <- 500


control <- trainControl(method='repeatedcv', 
                        number=5, 
                        repeats=3,
                        search = 'random')

#Random generate 15 mtry values with tuneLength = 15
set.seed(1)
rf_random <- train(price ~ .,
                   data = full_data,
                   method = 'rf',
                   metric = "MSE",
                   tuneLength  = 5, 
                   trControl = control)
print(rf_random)
```





# Attempt 1 # 5256 4932
```{r}
price_train_1 <- price_train %>% select(accommodates,bedrooms,beds,amenities,total_nearby_landmarks,In_Downtown,In_Delridge, In_Lake_City,price)
xval_1<- xval %>% select(accommodates,bedrooms,beds,amenities,total_nearby_landmarks,In_Downtown,In_Delridge, In_Lake_City)
dim(price_train_1)
dim(xval_1)
rf_oob_comp <- randomForest(formula = price~., 
                            data = price_train_1, xtest = xval_1, ytest = yval)

train.error.1 <-mean((rf_oob_comp$mse))
df <- data.frame(cbind(rf_oob_comp$predicted,price_train_1$price))
df$diff <- df$X1-df$X2
df
```



# Attempt 2 # 5340 4981

```{r}
price_train_2 <- price_train %>% select(accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,In_Delridge, In_Lake_City,price)
xval_2<- xval %>% select(accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,In_Delridge, In_Lake_City)
dim(price_train_2)
dim(xval_2)
rf_oob_comp_2 <- randomForest(formula = price~., 
                            data = price_train_2, xtest = xval_2, ytest = yval)

train.error_2 <-mean((rf_oob_comp_2$mse))
df <- data.frame(cbind(rf_oob_comp_2$predicted,price_train_2$price))
df$diff <- df$X1-df$X2
df
val.error.2 <- mean((rf_oob_comp_2$test$mse))

# Attempt 3 # 5266 4964
price_train_3 <- price_train %>% select(host_response_rate, accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,In_Delridge, In_Lake_City,price)
xval_3<- xval %>% select(host_response_rate,accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,In_Delridge, In_Lake_City)
dim(price_train_3)
dim(xval_3)
rf_oob_comp_3 <- randomForest(formula = price~., 
                            data = price_train_3, xtest = xval_3, ytest = yval)

train.error_3 <-mean((rf_oob_comp_3$mse))
df <- data.frame(cbind(rf_oob_comp_3$predicted,price_train_3$price))
df$diff <- df$X1-df$X2
df
val.error_3 <- mean((rf_oob_comp_3$test$mse))

# Attempt 4 #5077 4881
price_train_4 <- price_train %>% select(property_type, host_response_rate, accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,In_Delridge, In_Lake_City,price)
xval_4<- xval %>% select(property_type,host_response_rate,accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,In_Delridge, In_Lake_City)
rf_oob_comp_4 <- randomForest(formula = price~., 
                            data = price_train_4, xtest = xval_4, ytest = yval)

train.error_4 <-mean((rf_oob_comp_4$mse))
df <- data.frame(cbind(rf_oob_comp_4$predicted,price_train_4$price))
df$diff <- df$X1-df$X2
df
val.error_4 <- mean((rf_oob_comp_4$test$mse))

# Attempt 5 #4937 4791
price_train_5 <- price_train %>% select(room_type, property_type, host_response_rate, accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,In_Delridge, In_Lake_City,price)
xval_5<- xval %>% select(room_type, property_type,host_response_rate,accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,In_Delridge, In_Lake_City)
rf_oob_comp_5 <- randomForest(formula = price~., 
                            data = price_train_5, xtest = xval_5, ytest = yval)

train.error_5 <-mean((rf_oob_comp_5$mse))
df <- data.frame(cbind(rf_oob_comp_5$predicted,price_train_5$price))
df$diff <- df$X1-df$X2
df
val.error_5 <- mean(sqrt(rf_oob_comp_5$test$mse))
print(val.error_5)

# Attempt 6 # 4886 4651
price_train_6 <- price_train %>% select(instant_bookable,room_type, property_type, host_response_rate, accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,In_Delridge, In_Lake_City,price)
xval_6<- xval %>% select(instant_bookable,room_type, property_type,host_response_rate,accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,In_Delridge, In_Lake_City)
rf_oob_comp_6 <- randomForest(formula = price~., 
                            data = price_train_6, xtest = xval_6, ytest = yval)

train.error_6 <-mean((rf_oob_comp_6$mse))
df <- data.frame(cbind(rf_oob_comp_6$predicted,price_train_6$price))
df$diff <- df$X1-df$X2
df
val.error_6 <- mean(sqrt(rf_oob_comp_6$test$mse))
print(val.error_6)
mean(sqrt(rf_oob_comp_6$mse))
mean(sqrt(rf_oob_comp_6$test$mse))

# Attempt 7 #4676 4639
price_train_7 <- price_train %>% select(cancellation_policy,instant_bookable,room_type, property_type, host_response_rate, accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,In_Delridge, In_Lake_City,price)
xval_7<- xval %>% select(cancellation_policy,instant_bookable,room_type, property_type,host_response_rate,accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,In_Delridge, In_Lake_City)
rf_oob_comp_7 <- randomForest(formula = price~., 
                            data = price_train_7, xtest = xval_7, ytest = yval)

train.error_7 <-mean((rf_oob_comp_7$mse))
df <- data.frame(cbind(rf_oob_comp_7$predicted,price_train_7$price))
df$diff <- df$X1-df$X2
df
val.error_7 <- mean(sqrt(rf_oob_comp_7$test$mse))
print(val.error_7)

# Attempt 8 #4528 4380
price_train_8 <- price_train %>% select(neighbourhood_group_cleansed,cancellation_policy,instant_bookable,room_type, property_type, host_response_rate, accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,In_Delridge, In_Lake_City,price)
xval_8<- xval %>% select(neighbourhood_group_cleansed,cancellation_policy,instant_bookable,room_type, property_type,host_response_rate,accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,In_Delridge, In_Lake_City)
rf_oob_comp_8 <- randomForest(formula = price~., 
                            data = price_train_8, xtest = xval_8, ytest = yval)

train.error_8 <-mean((rf_oob_comp_8$mse))
df <- data.frame(cbind(rf_oob_comp_8$predicted,price_train_8$price))
df$diff <- df$X1-df$X2
df

val.error_8 <- mean(sqrt(rf_oob_comp_8$test$mse))
print(val.error_8)

# Attempt 9 # 4608 4362
price_train_9 <- price_train %>% select(neighbourhood_group_cleansed,cancellation_policy,room_type, property_type, host_response_rate, accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,In_Delridge, In_Lake_City,price)
xval_9<- xval %>% select(neighbourhood_group_cleansed,cancellation_policy,room_type, property_type,host_response_rate,accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,In_Delridge, In_Lake_City)
rf_oob_comp_9 <- randomForest(formula = price~., 
                            data = price_train_9, xtest = xval_9, ytest = yval,ntree=490)

train.error_9 <-mean((rf_oob_comp_9$mse))
df <- data.frame(cbind(rf_oob_comp_9$predicted,price_train_9$price))
df$diff <- df$X1-df$X2
df

val.error_9 <- mean(sqrt(rf_oob_comp_9$test$mse))
mean(rf_oob_comp_9$test$mse)
print(val.error_9)

# Attempt 10 # 4593 4341
price_train_10 <- price_train %>% select(neighbourhood_group_cleansed,cancellation_policy,room_type, property_type, host_response_rate, accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,price)
xval_10<- xval %>% select(neighbourhood_group_cleansed,cancellation_policy,room_type, property_type,host_response_rate,accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,)
rf_oob_comp_10 <- randomForest(formula = price~., 
                            data = price_train_10, xtest = xval_10, ytest = yval)

train.error_10 <-mean((rf_oob_comp_10$mse))
df <- data.frame(cbind(rf_oob_comp_10$predicted,price_train_10$price))
df$diff <- df$X1-df$X2
df

val.error_10 <- mean(sqrt(rf_oob_comp_10$test$mse))
print(val.error_10)
plot(select(price,"price","host_response_rate")

```


```{r plot price vs. predictor variables}
for (i in 1:ncol(price)){
  plot(x=price[,i],y=price$price,main = paste("Price vs.",colnames(price)[i]),xlab = colnames(price[i]))
}
```

```{r}
#tune models
library(caret)
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
tunegrid <- expand.grid(.mtry=c(1:15))
rf_gridsearch <- train(price~., data=price_train_9, method="rf", metric="RMSE", tuneGrid=tunegrid, trControl=control)
print(rf_gridsearch)
plot(rf_gridsearch)
library(randomForest)
nrow(price_train_9)
bestmtry <- tuneRF(x = price_train_9[,-ncol(price_train_9)],y=price_train_9[,ncol(price_train_9)] , stepFactor=1.5, improve=1e-5, ntree=500)
rf_oob_comp_9_tune <- randomForest(formula = price~., 
                            mtry = 4, nodesize = 1, data = price_train_9, xtest = xval_9, ytest = yval,ntree=490)
val.error_9 <- mean(sqrt(rf_oob_comp_9$test$mse))
print(val.error_9)

```

```{r}
nodesizes <- seq(1000,4000,by=200)
MSEs <- vector()
var.train <- vector()
var.val <- vector()
for (i in 1:length(nodesizes)){
  rf_oob_comp_8_tune <- randomForest(formula = price~., mtry = 3, 
                                     nodesize = 1200,
                              data = price_train_8, xtest = xval_8, ytest = yval)
  MSEs[i] <- rf_oob_comp_8_tune$test$mse 
  var.train[i] <- mean(rf_oob_comp_8_tune$rsq)
  var.val[i] <- mean(rf_oob_comp_8_tune$test$rsq)
}

plot(MSEs)
lines(1:length(MSEs), MSEs, xlim=range(15), ylim=range(MSEs), pch=16)
plot(1:length(MSEs), var.train, xlim=range(15), ylim=range(var.train), pch=16,col="red")
lines(1:length(MSEs), var.val, xlim=range(15), ylim=range(var.val), pch=16,col="green")
nodesizes[which.min(MSEs)]


train.error_8 <-mean(sqrt(rf_oob_comp_8_tune$mse))
df <- data.frame(cbind(rf_oob_comp_8_tune$predicted,price_train_8$price))
df$diff <- df$X1-df$X2

```

```{r tune the best model }
nfold <- 5 
n <- nrow(price)
cases <-  sample(rep(1:nfold,ceiling(n/nfold))[1:n])
train.MSEs <- matrix(nrow = 4, ncol = 20)
val.MSEs <- matrix(nrow = 4, ncol = 20)
for (mtry in c(3:4)){
  for (nodesize in c(10:20)){
      val.mse <- 0 
      train.mse <- 0 
      for (fold in 1:nfold){
          train <- price[cases!=fold,]
          test <-  price[cases==fold,]
          rf_oob_comp_9_tune <- randomForest(formula = price~., 
                                          data=train,
                                          mtry=mtry,nodesize=nodesize)
          train.mse <- train.mse + mean(sqrt(rf_oob_comp_9_tune$mse))
          y.hat_9 <- predict(object = rf_oob_comp_9_tune, newdata = test)
          val.error_9<- mean(sqrt((y.hat_9-yval)^2))
          val.mse <- val.mse + val.error_9 
      }
  val.MSEs[mtry,nodesize] <- val.mse/nfold
  train.MSEs[mtry,nodesize] <- train.mse/nfold
    }
}

rf_oob_comp_10_tune <- randomForest(formula = price~., data = price_train_10)
y.hat_10<- predict(object = rf_oob_comp_10_tune, newdata = xval_10)
val.error_10<- mean(sqrt((y.hat_10-yval)^2))
print(val.error_10)

plot(val.MSEs[3:4,10:20])
train.MSEs[3:4,10:20]


```

```{r}
classifier <- randomForest(as.factor(price)~., data=price_train[,-1], ntree=400, importance=T)

train_error <- mean(predict(classifier) - train$price)
imp <- importance(classifier, type=1, scale = F)
imp <- imp %>% as.data.frame 
colnames(imp) <- c("var","accu")
imp %>% arrange(MeanDecreaseAccuracy)
var_importance <- data_frame(variable=row.names(imp),
                             importance=as.vector(imp))
var_importance <- arrange(var_importance, importance)
var_importance$variable <- factor(var_importance$variable, levels=var_importance$variable)

p <- ggplot(var_importance, aes(x=variable, weight=importance))
p <- p + geom_bar() + coord_flip() + ylab("Variable Importance")
p <- p + scale_fill_discrete(name="Variable Name") + ggtitle("Variable Importance from Random Forest Fit")
p + theme_bw() + 
  theme(axis.text = element_text(color = "darkslategrey"),
        text = element_text(color = "black", size = 10), legend.key.size = unit(5, "lines"))
   

```

total_nearby_landmarks
host_listing_count 3.79 
accommodates 1.79 
neighborhood_group_cleansed 1.86 
property 1.83 
room type 1.96
guests included 
bedrooms 1.28
amenities 1.39
cleaning_fee 3.05
cancellation policy 2.1 
total_nearby_landmarks 1.47
```{r}
colnames(price)
length(rf_oob_comp_11$mse)
length(price_train_11$price)
length(y.hat)
plot(rf_oob_comp_11$mse,price_train_11$price)
price_train_11 <- price_train %>% select(total_nearby_landmarks,host_listings_count, accommodates, neighbourhood_group_cleansed, property_type, room_type, guests_included, bedrooms, amenities, cleaning_fee, cancellation_policy,price)
xval_11<- xval %>% select(total_nearby_landmarks,host_listings_count, accommodates, neighbourhood_group_cleansed, property_type, room_type, guests_included, bedrooms, amenities, cleaning_fee, cancellation_policy)
rf_oob_comp_11 <- randomForest(formula = price~., 
                            data = price_train_11)
y.hat.train <- predict(rf_oob_comp_11, price_train_11)
plot(y.hat.train)
y.hat <- predict(rf_oob_comp_11, xval_11)
print(mean((y.hat-yval)^2))
print((mean(rf_oob_comp_11$mse)))

length(rf_oob_comp_11$predicted)
train.error_11 <-mean((rf_oob_comp_11$mse))
df <- data.frame(cbind(rf_oob_comp_11$predicted,price_train_11$price))
df$diff <- df$X1-df$X2
df

val.error_11 <- mean(sqrt(rf_oob_comp_11$test$mse))
mean(rf_oob_comp_11$test$mse)
print(val.error_11)
```

```{r}
# Attempt 9 # 4608 4362
select(total_nearby_landmarks,host_listings_count, accommodates, neighbourhood_group_cleansed, property_type, room_type, guests_included, bedrooms, amenities, cleaning_fee, cancellation_policy,price)


price_train_12 <- price_train %>% select(cancellation_policy,host_listings_count,cleaning_fee, neighbourhood_group_cleansed,cancellation_policy,room_type, property_type, host_response_rate, accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown,price)
xval_12<- xval %>% select(cancellation_policy,host_listings_count,cleaning_fee,neighbourhood_group_cleansed,cancellation_policy,room_type, property_type,host_response_rate,accommodates,bedrooms,beds,total_nearby_landmarks,In_Downtown)
rf_oob_comp_12 <- randomForest(formula = price~., 
                            data = price_train_12, xtest = xval_12, ytest = yval,ntree=490)

train.error_12 <-mean((rf_oob_comp_12$mse))
df <- data.frame(cbind(rf_oob_comp_12$predicted,price_train_12$price))
df$diff <- df$X1-df$X2
df

val.error_12 <- mean(sqrt(rf_oob_comp_12$test$mse))
mean(rf_oob_comp_12$test$mse)
print(val.error_12)
```



#Final prediction

```{r}
saveRDS(m2, "./m2_model.rds")

# later...

# load the model
super_model <- readRDS("./m2_model.rds")

# make a predictions on "new data" using the final model
final_predictions <- predict(super_model, price_test[, colnames(price_test)!="price"])

mean((final_predictions - price_test$price)^2)
```

